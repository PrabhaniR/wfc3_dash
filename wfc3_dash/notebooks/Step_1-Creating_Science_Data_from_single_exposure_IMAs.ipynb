{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to Use `wfc_dash` on DASH data: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Table of Contents - Notebook 1: <br> \n",
    "1. <a href='#introduction'>Introduction</a>\n",
    "2. <a href='#imports'>Imports</a>\n",
    "3. <a href='#downloads'>Downloading Relevant Data </a>\n",
    "4. <a href='#DASH'>Running DASH </a> <br>\n",
    "    a) <a href='#object'> Creating DashData object <br> </a>\n",
    "    b) <a href='#diff_files'> Create diff files from Reads <br> </a>\n",
    "    c) <a href='#asn_table'> Create association table <br> </a>\n",
    "    e) <a href='#subtract_ext'> Subtract background from new FLT's <br> </a>\n",
    "    f) <a href='#cosmic_rays'> Fix cosmic rays <br> </a>\n",
    "    g) <a href='#align_each_other'> Align reads to each other <br> </a> <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction  <a id='introduction'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is the first in a new DASH pipeline workflow developed to ease the process of reducing DASH data. The pipeline is customizable, able to be changed according to scientific goals of the user, and this first tutorial walks the user from data download to a finished product ready for science analysis.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports <a id='imports'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from astroquery.mast import Observations\n",
    "from astropy.io import fits \n",
    "from astropy.table import Table\n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np\n",
    "\n",
    "from astropy.io import ascii\n",
    "\n",
    "from glob import glob\n",
    "from drizzlepac import astrodrizzle\n",
    "\n",
    "import os\n",
    "\n",
    "%matplotlib notebook "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloading some relevant data <a id='downloads'></a>\n",
    "\n",
    "#### Get the table of observations associated with 15238 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obsTable = Observations.query_criteria(proposal_id=['15238'], obs_id=['IDNM0J030'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get the full list of products associated to the table and restrict the list to IMA files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_list = Observations.get_product_list(obsTable)\n",
    "BM = (product_list['productSubGroupDescription']  == 'IMA') \n",
    "product_list = product_list[BM]\n",
    "\n",
    "product_list.show_in_notebook(display_length=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pick a single exposure file to work on - to create usable data you will have to follow this work flow on all individual IMA files in your dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myID = product_list['obsID'][0:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download the IMA and FLT files for that exposure. The standard pipeline-FLT will be used for comparison with the detrended final product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "download = Observations.download_products(myID,mrp_only=False,productSubGroupDescription=['IMA','FLT'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display the results of the download operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "download"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read the files that were just downloaded locally "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#have path be everything minus last 8 characters (ima.fits)\n",
    "localpathtofile = download['Local Path'][0][:-8]\n",
    "localpathtofile\n",
    "\n",
    "original_ima = fits.open(localpathtofile+'ima.fits')\n",
    "original_flt = fits.open(localpathtofile+'flt.fits')\n",
    "original_ima.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot the individual reads of the IMA file\n",
    "Note: the individual 'SCI' extensions are stored in reverse order, with 'SCI', 1 corresponding to the last read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nsamp = original_ima[0].header['NSAMP']\n",
    "print('NSAMP',nsamp)\n",
    "fig,axarr = plt.subplots((nsamp+3)//4,4, figsize=(9,3*((nsamp+3)//4)))\n",
    "\n",
    "for i in range(1,4*((nsamp+3)//4)+1):\n",
    "\n",
    "    row = (i-1)//4\n",
    "    col = (i-1)%4\n",
    "    if (i <= nsamp):\n",
    "        immed = np.nanmedian(original_ima['SCI',i].data)\n",
    "        stdev = np.nanstd(original_ima['SCI',i].data)\n",
    "        axarr[row,col].imshow(original_ima['SCI',i].data,clim=[immed-.3*stdev,immed+.5*stdev],cmap='Greys',origin='lower')\n",
    "        axarr[row,col].set_title('SCI '+str(i))\n",
    "        axarr[row,col].set_xticks([]) \n",
    "        axarr[row,col].set_yticks([]) \n",
    "    else:\n",
    "        fig.delaxes(axarr[row,col])\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the individual steps of the DASH pipeline <a id='DASH'></a>\n",
    "Run the DASH pipeline for a single exposure.  \n",
    "This procedure showcases the capabilities and customization options of the DASH pipeline.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This cell is inserted temporarily to allow for relative imports until the `wfc3_dash` submodule is properly packaged and installed within the `wfc3_tools` module. The following will only work if you are using the notebooks inside of the Notebook directory. \n",
    "\n",
    "#### If you move the notebooks and want to use them elsewhere you can still provide a `temp_path` to the dash codes and remove the `#` from the commented out portion below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "#tmp_path = \".../wfc3_dash/wfc3_dash\"\n",
    "#if tmp_path not in sys.path:\n",
    "    #sys.path.append(tmp_path)\n",
    "\n",
    "from reduce_dash import DashData"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Create a DashData object using the path to the IMA file we have downloaded above\n",
    "<a id='object'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myDash = DashData(localpathtofile+'ima.fits', flt_file_name=localpathtofile+'flt.fits')\n",
    "print(myDash.root)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Create diff files <a id='diff_files'></a>\n",
    "\n",
    "A diff file contains the counts accumulated between two reads of the IMA file.\n",
    "\n",
    "The diff files are written to disk in a directory named ./diff under the current working directory (cwd).  \n",
    "\n",
    "In creating diff files from the readouts of the IMA, the first difference, between the 1-st and 0-th read is ignored because of its very short exposure time of 2.9 seconds, resulting in a noisy image.\n",
    "\n",
    "In order to create a correct error extension, the split_ima() method calls the utils.get_flat() function and the utils.get_IDCtable function.  \n",
    "\n",
    "The get_flat() function reads the name of the flat field used for calibrating the IMA images from the IMA file header.  \n",
    "The get_IDCtable() function reads the name of the image distortion correction table, a reference file containing distortion coefficients that are used to correct for distortion in drizzled data products.\n",
    "\n",
    "If the flat file is not present locally in a directory named ./iref under the cwd, get_flat() will download   \n",
    "the flat field file from the CRDS database https://hst-crds.stsci.edu/unchecked_get/references/hst/ \n",
    "and place it in ./iref . Similarly for the IDCTAB reference file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myDash.split_ima()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot the diff files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndiff = len(myDash.diff_files_list)\n",
    "print('Number of diff files',ndiff)\n",
    "\n",
    "if ndiff > 4: \n",
    "    fig,axarr = plt.subplots((ndiff+3)//4,4, figsize=(9,3*((ndiff+3)//4)))\n",
    "\n",
    "    for i in range(4*((ndiff+3)//4)):\n",
    "\n",
    "        row = (i)//4\n",
    "        col = (i)%4\n",
    "        if (i < ndiff):\n",
    "            diff_i = fits.open(myDash.diff_files_list[i]+'_diff.fits')\n",
    "            immed = np.nanmedian(diff_i['SCI'].data)\n",
    "            stdev = np.nanstd(diff_i['SCI'].data)\n",
    "            axarr[row,col].imshow(diff_i['SCI'].data,clim=[immed-.3*stdev,immed+.5*stdev],cmap='Greys',origin='lower')\n",
    "            axarr[row,col].set_title('Diff:'+str(i+1))\n",
    "            axarr[row,col].set_xticks([]) \n",
    "            axarr[row,col].set_yticks([]) \n",
    "        else:\n",
    "            fig.delaxes(axarr[row,col])\n",
    "else:\n",
    "    fig,axarr = plt.subplots(1,ndiff,figsize=(15,15))\n",
    "    for i in range(ndiff):\n",
    "        immed = np.nanmedian(diff_i['SCI'].data)\n",
    "        stdev = np.nanstd(diff_i['SCI'].data)\n",
    "        diff_i = fits.open(myDash.diff_files_list[i]+'_diff.fits')\n",
    "        axarr[i].imshow(diff_i['SCI'].data,clim=[immed-.3*stdev,immed+.5*stdev],cmap='Greys',origin='lower')\n",
    "        axarr[i].set_title('Diff:'+str(i+1))\n",
    "        axarr[i].set_xticks([]) \n",
    "        axarr[i].set_yticks([]) \n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Create an association file <a id='asn_table'></a>\n",
    "\n",
    "This file mimics a typical association file for dithered exposures, which is used by Astrodrizzle to align and stack multiple exposures taken at the same sky position with small dithers. \n",
    "\n",
    "We exploit the fact that a WFC3/IR exposure taken under gyro control can be effectively split into individual pseudo-exposures (the diff images we created in the step before). From there, Astrodrizzle can treat such pseudo-expsoures as individual dithers, and combine them into a single exposure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myDash.make_pointing_asn()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Show the content of the asn file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asn_filename = 'diff/{}_asn.fits'.format(myDash.root)\n",
    "asn_table = Table(fits.getdata(asn_filename, ext=1))\n",
    "asn_table.show_in_notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Create Segmentation Map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create segmentation map from original FLT\n",
    "Make segmentation map from original FLT image to assist with background subtraction and fixing of cosmic ray flags.  \n",
    "We first use `create_seg_map()` to create a segmentation map from the original FLT file using `photutils`.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myDash.create_seg_map()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### View segmentation map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rootname = myDash.root\n",
    "segmap_name = ('segmentation_maps/'+ rootname + '_seg.fits')\n",
    "segmap = fits.getdata(segmap_name)\n",
    "print(segmap_name)\n",
    "fig = plt.figure(figsize=(6, 8))\n",
    "plt.imshow(segmap, origin='lower', vmin=0, vmax=1, cmap='Greys_r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Print and read source list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sourcelist_name = ('segmentation_maps/' + rootname + '_source_list.dat')\n",
    "sourcelist = ascii.read(sourcelist_name)\n",
    "print(sourcelist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create segmentation map and source list from diff files\n",
    "Make source lists from our difference files created from the IMA so that `TweakReg` can better align these difference files to catalogs, each other, etc.\n",
    "The function `diff_seg_map` needs a list of difference files that contain the full path name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diffpath = os.path.dirname(os.path.abspath('diff/{}_*_diff.fits'.format(rootname)))\n",
    "cat_images=sorted([os.path.basename(x) for x in glob('diff/{}_*_diff.fits'.format(rootname))])\n",
    "\n",
    "sc_diff_files = [diffpath + '/' + s for s in cat_images]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myDash.diff_seg_map(cat_images=sc_diff_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segmap_name = ('segmentation_maps/' + rootname + '_01_diff_seg.fits')\n",
    "segmap = fits.getdata(segmap_name)\n",
    "print(segmap_name)\n",
    "fig = plt.figure(figsize=(6, 8))\n",
    "plt.imshow(segmap, origin='lower', vmin=0, vmax=1, cmap='Greys_r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Subtract Background from diff files <a id='subtract_ext'></a>\n",
    "Subtract background from the individual reads taken from the original IMA file using the DRZ and SEG images produced in the background subtraction of the original FLT.  \n",
    "By default, this function will subtract the background and write it to the header. Setting parameter subtract to `False` will not subtract the background and only write it to the header.  \n",
    "Set parameter `reset_stars_dq` to `True` to reset cosmic rays within objects to 0 (because the centers of the stars are flagged)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myDash.subtract_background_reads()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Fix Cosmic Rays <a id='cosmic_rays'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myDash.fix_cosmic_rays()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Align reads to each other  <a id='align_each_other'></a>\n",
    "Align reads from the IMA to one another by aligning each difference file to the first diff file.  \n",
    "\n",
    "Uses `TweakReg` to update the WCS information in the headers of the diff files, then drizzles the images together using `Astrodrizzle`.  \n",
    "\n",
    "Refer to documentation to customize parameters for `TweakReg` and `AstroDrizzle`. \n",
    "\n",
    "(`NOTE: UnboundLocalError: local variable 'sig' referenced before assignment` --> Can be solved by lowering threshold parameter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myDash.align(updatehdr=False, updatewcs=True, astrodriz=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the shifts file to analyze how well the alignment went.\n",
    "Do not update header until shifts are satisfactory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shift_file = glob('shifts/shifts_*.txt')\n",
    "print(open(shift_file[0]).read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Update header and WCS information, then plot final drizzled image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Listed below are all the inputs available through the function call to `myDash.align()` which runs `TweakReg` and `AstroDrizzle`; there are more inputs available to users when working with `TweakReg` and `Astrodrizzle` that could be an integral part of the workflow for users of DASH. The example below lists the automatic values set for every input: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```myDash.align(self, subtract_background = True, \n",
    "            align_method = None, \n",
    "            ref_catalog = None, \n",
    "            create_diff_source_lists = True,\n",
    "            updatehdr = True, \n",
    "            updatewcs = True, \n",
    "            wcsname = 'DASH', \n",
    "            threshold = 50., \n",
    "            cw = 3.5, \n",
    "            searchrad = 20., \n",
    "            astrodriz = True, \n",
    "            cat_file = 'catalogs/diff_catfile.cat',\n",
    "            drz_output = None, \n",
    "            move_files = False)```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myDash.align(threshold = 20.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sci_name = myDash.root + '_drz_sci.fits'\n",
    "og_flt_name = 'mastDownload/HST/' + myDash.root + '/' + myDash.root + '_ima.fits'\n",
    "sci = fits.getdata(sci_name)\n",
    "og_flt = fits.getdata(og_flt_name)\n",
    "\n",
    "fig = plt.figure(figsize=(7, 5))\n",
    "ax1 = fig.add_subplot(1,2,2)\n",
    "ax2 = fig.add_subplot(1,2,1)\n",
    "\n",
    "ax1.set_title('DASH Pipeline Reduced Science File')\n",
    "ax2.set_title('Original IMA (not reduced using pipeline)')\n",
    "\n",
    "ax1.imshow(sci, vmin=0, vmax=40, cmap='Greys_r', origin='lower')\n",
    "ax2.imshow(og_flt, vmin=0, vmax=40, cmap='Greys_r', origin='lower');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
