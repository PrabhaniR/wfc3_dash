{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from astroquery.mast import Observations\n",
    "from astropy.io import fits \n",
    "from astropy.table import Table\n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np\n",
    "\n",
    "from astropy.io import ascii\n",
    "\n",
    "from glob import glob\n",
    "from drizzlepac import astrodrizzle\n",
    "\n",
    "import os\n",
    "\n",
    "%matplotlib notebook "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloading some relevant data\n",
    "\n",
    "#### Get the table of observations associated with 15238 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obsTable = Observations.query_criteria(proposal_id=['15238'], obs_id=['IDNM0J030'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get the full list of products associated to the table and restrict the list to IMA files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_list = Observations.get_product_list(obsTable)\n",
    "BM = (product_list['productSubGroupDescription']  == 'IMA') \n",
    "product_list = product_list[BM]\n",
    "\n",
    "product_list.show_in_notebook(display_length=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pick a single exposure file to work on - to create usable data you will have to follow this work flow on all individual IMA files in your dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myID = product_list['obsID'][0:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download the IMA and FLT files for that exposure. The standard pipeline-FLT will be used for comparison with the detrended final product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "download = Observations.download_products(myID,mrp_only=False,productSubGroupDescription=['IMA','FLT'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display the results of the download operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "download"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read the files that were just downloaded locally "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#have path be everything minus last 8 characters (ima.fits)\n",
    "localpathtofile = download['Local Path'][0][:-8]\n",
    "localpathtofile\n",
    "\n",
    "original_ima = fits.open(localpathtofile+'ima.fits')\n",
    "original_flt = fits.open(localpathtofile+'flt.fits')\n",
    "original_ima.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot the individual reads of the IMA file\n",
    "Note: the individual 'SCI' extensions are stored in reverse order, with 'SCI', 1 corresponding to the last read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nsamp = original_ima[0].header['NSAMP']\n",
    "print('NSAMP',nsamp)\n",
    "fig,axarr = plt.subplots((nsamp+3)//4,4, figsize=(9,3*((nsamp+3)//4)))\n",
    "\n",
    "for i in range(1,4*((nsamp+3)//4)+1):\n",
    "\n",
    "    row = (i-1)//4\n",
    "    col = (i-1)%4\n",
    "    if (i <= nsamp):\n",
    "        immed = np.nanmedian(original_ima['SCI',i].data)\n",
    "        stdev = np.nanstd(original_ima['SCI',i].data)\n",
    "        axarr[row,col].imshow(original_ima['SCI',i].data,clim=[immed-.3*stdev,immed+.5*stdev],cmap='Greys',origin='lower')\n",
    "        axarr[row,col].set_title('SCI '+str(i))\n",
    "        axarr[row,col].set_xticks([]) \n",
    "        axarr[row,col].set_yticks([]) \n",
    "    else:\n",
    "        fig.delaxes(axarr[row,col])\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the individual steps of the DASH pipeline\n",
    "Run the DASH pipeline for a single exposure.  \n",
    "This procedure showcases the capabilities and customization options of the DASH pipeline.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This cell is inserted temporarily to allow for relative imports until the whole wfc3_dash submodule is properly packaged and installed within the wfc3_tools module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "from reduce_dash import DashData"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Create a DashData object using the path to the IMA file we have downloaded above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myDash = DashData(localpathtofile+'ima.fits', flt_file_name=localpathtofile+'flt.fits')\n",
    "print(myDash.root)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Create diff files\n",
    "\n",
    "A diff file contains the counts accumulated between two reads.  \n",
    "The diff files are written to disk in a directory named ./diff under the current working directory (cwd).  \n",
    "In creating diff files, the first difference, between the 1-st and 0-th read is ignored becuase of   \n",
    "its very short expsoure time of 2.9 seconds, resulting in a noisy image.\n",
    "\n",
    "In order to create a correct error extension, the split_ima() method calls the utils.get_flat() function and the utils.get_IDCtable function.  \n",
    "The get_flat function reads the name of the flat field used for calibrating the ima images from the ima file header.  \n",
    "The get_IDCtable reads the name of image distortion correction table, a reference file containing distortion coefficients that are used to correct for distortion in MAST drizzled data products.  \n",
    "If the flat file is not present locally in a directory named ./iref under the cwd, get_flat() will download   \n",
    "the flat field file from the CRDS database https://hst-crds.stsci.edu/unchecked_get/references/hst/ \n",
    "and place it in ./iref . Similarly for the IDCTAB reference file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myDash.split_ima()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot the diff files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndiff = len(myDash.diff_files_list)\n",
    "print('Number of diff files',ndiff)\n",
    "\n",
    "if ndiff > 4: \n",
    "    fig,axarr = plt.subplots((ndiff+3)//4,4, figsize=(9,3*((ndiff+3)//4)))\n",
    "\n",
    "    for i in range(4*((ndiff+3)//4)):\n",
    "\n",
    "        row = (i)//4\n",
    "        col = (i)%4\n",
    "        if (i < ndiff):\n",
    "            diff_i = fits.open(myDash.diff_files_list[i]+'_diff.fits')\n",
    "            immed = np.nanmedian(diff_i['SCI'].data)\n",
    "            stdev = np.nanstd(diff_i['SCI'].data)\n",
    "            axarr[row,col].imshow(diff_i['SCI'].data,clim=[immed-.3*stdev,immed+.5*stdev],cmap='Greys',origin='lower')\n",
    "            axarr[row,col].set_title('Diff:'+str(i+1))\n",
    "            axarr[row,col].set_xticks([]) \n",
    "            axarr[row,col].set_yticks([]) \n",
    "        else:\n",
    "            fig.delaxes(axarr[row,col])\n",
    "else:\n",
    "    fig,axarr = plt.subplots(1,ndiff,figsize=(15,15))\n",
    "    for i in range(ndiff):\n",
    "        immed = np.nanmedian(diff_i['SCI'].data)\n",
    "        stdev = np.nanstd(diff_i['SCI'].data)\n",
    "        diff_i = fits.open(myDash.diff_files_list[i]+'_diff.fits')\n",
    "        axarr[i].imshow(diff_i['SCI'].data,clim=[immed-.3*stdev,immed+.5*stdev],cmap='Greys',origin='lower')\n",
    "        axarr[i].set_title('Diff:'+str(i+1))\n",
    "        axarr[i].set_xticks([]) \n",
    "        axarr[i].set_yticks([]) \n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Create an association file\n",
    "\n",
    "This file mimics a typical association file for dithered exposures, that is used by astrodrizzle   \n",
    "to align and stack multiple exposures taken at the same sky position with small dithers.  \n",
    "We exploit the fact that a WFC3/IR exposure taken under gyro control can be effectively split into   \n",
    "individual pseudo-exposures (the diff images).  \n",
    "Astrodrizzle can treat such pseudo-expsoures as individual dithers, and combine them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myDash.make_pointing_asn()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Show the content of the asn file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asn_filename = 'diff/{}_asn.fits'.format(myDash.root)\n",
    "asn_table = Table(fits.getdata(asn_filename, ext=1))\n",
    "asn_table.show_in_notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Create Segmentation Map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create segmentation map from original FLT\n",
    "Make segmentation map from original FLT image to assist with background subtraction and fixing of cosmic ray flags.  \n",
    "We first use `create_seg_map` to create a segmentation map from the original FLT file using `photutils`.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myDash.create_seg_map()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### View segmentation map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rootname = myDash.root\n",
    "segmap_name = ('segmentation_maps/'+ rootname + '_seg.fits')\n",
    "segmap = fits.getdata(segmap_name)\n",
    "print(segmap_name)\n",
    "fig = plt.figure(figsize=(6, 8))\n",
    "plt.imshow(segmap, origin='lower', vmin=0, vmax=1, cmap='Greys_r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Print and read source list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sourcelist_name = ('segmentation_maps/' + rootname + '_source_list.dat')\n",
    "sourcelist = ascii.read(sourcelist_name)\n",
    "print(sourcelist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create segmentation map and source list from diff files\n",
    "Make source lists from our difference files created from the IMA so that `TweakReg` can better align these difference files to catalogs, each other, etc.\n",
    "The function `diff_seg_map` needs a list of difference files that contain the full path name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diffpath = os.path.dirname(os.path.abspath('diff/{}_*_diff.fits'.format(rootname)))\n",
    "cat_images=sorted([os.path.basename(x) for x in glob('diff/{}_*_diff.fits'.format(rootname))])\n",
    "\n",
    "sc_diff_files = [diffpath + '/' + s for s in cat_images]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myDash.diff_seg_map(cat_images=sc_diff_files,overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segmap_name = ('segmentation_maps/' + rootname + '_01_diff_seg.fits')\n",
    "segmap = fits.getdata(segmap_name)\n",
    "print(segmap_name)\n",
    "fig = plt.figure(figsize=(6, 8))\n",
    "plt.imshow(segmap, origin='lower', vmin=0, vmax=1, cmap='Greys_r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Subtract Background from diff files\n",
    "Subtract background from the individual reads taken from the original IMA file using the DRZ and SEG imaged produced in the background subtraction of the original FLT.  \n",
    "By default, this function will subtract the background and write it to the header. Setting parameter subtract to False will not subtract the background and only write it to the header.  \n",
    "Set parameter reset_stars_dq to True to reset cosmic rays within objects to 0 (because the centers of the stars are flagged)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myDash.subtract_background_reads()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Fix Cosmic Rays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myDash.fix_cosmic_rays()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Align reads to each other\n",
    "Align reads to one another by aligning each to the first diff file.  \n",
    "\n",
    "Uses TweakReg to update the WCS information in the headers of the diff files, then drizzles the images together using Astrodrizzle.  \n",
    "\n",
    "Refer to documentation to customize parameters for TweakReg and AstroDrizzle. \n",
    "\n",
    "(`NOTE: UnboundLocalError: local variable 'sig' referenced before assignment` --> Can be solved by lowering threshold parameter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myDash.align(updatehdr=False, updateWCS=False, astrodriz=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the shifts file to analyze how well the alignment went.\n",
    "Do not update header until shifts are satisfactory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shift_file = glob('shifts/shifts_*.txt')\n",
    "print(open(shift_file[0]).read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Update header and WCS information, then plot final drizzled image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Listed below are all the inputs available through the function call to `myDash.align()` which runs `TweakReg` and `AstroDrizzle`; there are more inputs available to users when working with `TweakReg` and `Astrodrizzle` that could be an integral part of the workflow for users of DASH. The example in this "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```myDash.align(self, subtract_background = True, \n",
    "            align_method = None, \n",
    "            ref_catalog = None, \n",
    "            create_diff_source_lists = True,\n",
    "            updatehdr = True, \n",
    "            updateWCS = True, \n",
    "            wcsname = 'DASH', \n",
    "            threshold = 50., \n",
    "            cw = 3.5, \n",
    "            searchrad = 20., \n",
    "            astrodriz = True, \n",
    "            cat_file = 'catalogs/diff_catfile.cat',\n",
    "            drz_output = None, \n",
    "            move_files = False)```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myDash.align(threshold = 20.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sci_name = myDash.root + '_drz_sci.fits'\n",
    "og_flt_name = 'mastDownload/HST/' + myDash.root + '/' + myDash.root + '_ima.fits'\n",
    "sci = fits.getdata(sci_name)\n",
    "og_flt = fits.getdata(og_flt_name)\n",
    "\n",
    "fig = plt.figure(figsize=(20, 10))\n",
    "ax1 = fig.add_subplot(1,2,2)\n",
    "ax2 = fig.add_subplot(1,2,1)\n",
    "\n",
    "ax1.set_title('DASH Pipeline Reduced Science File')\n",
    "ax2.set_title('Original IMA (not reduced using pipeline)')\n",
    "\n",
    "ax1.imshow(sci, vmin=0, vmax=40, cmap='Greys_r', origin='lower', aspect=\"auto\")\n",
    "ax2.imshow(og_flt, vmin=0, vmax=40, cmap='Greys_r', origin='lower', aspect=\"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
